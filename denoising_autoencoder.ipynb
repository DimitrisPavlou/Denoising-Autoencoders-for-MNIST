{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "1yFiv9BlOcTB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D , MaxPooling2D , Flatten , Dense , Reshape , Input, Conv2DTranspose\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.decomposition import PCA\n",
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "EObSUZFrOzuC"
      },
      "outputs": [],
      "source": [
        "\n",
        "#load the mnist database\n",
        "\n",
        "(X_train , y_train ) , (X_test , y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "#regularize the data\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "#standardize\n",
        "X_train = (X_train - X_train.mean())/X_train.std()\n",
        "X_test = (X_test - X_test.mean())/X_test.std()\n",
        "\n",
        "#one hot encode y_train and y_test\n",
        "y_train = to_categorical(y_train , num_classes = 10)\n",
        "y_test = to_categorical(y_test , num_classes = 10)\n",
        "\n",
        "#add gaussian noise to the data (with mean = 0 and std = noise_factor)\n",
        "noise_factor = 0.8\n",
        "X_train_noisy = X_train + noise_factor*tf.random.normal(shape = X_train.shape)\n",
        "X_test_noisy = X_test + noise_factor*tf.random.normal(shape = X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "SSNj3e5uO1PM"
      },
      "outputs": [],
      "source": [
        "#function that returns a smaller version of the train(or test) set with n_per_class number of samples per class\n",
        "\n",
        "def batch_XY(X , y , n_per_class) :\n",
        "    labels = np.unique(y)           #find the unique labels\n",
        "    X_batch , y_batch = [] , []     #create empty lists\n",
        "    for label in labels :\n",
        "\n",
        "        indices = np.where(y == label)[0]           #find where y == label\n",
        "        selected_indices = np.random.choice(indices , n_per_class)  #pick n_per_class of the items found in the indices of the previous line randomly\n",
        "        X_batch.extend(X[selected_indices])                         #append to the corresponding lists\n",
        "        y_batch.extend(y[selected_indices])\n",
        "\n",
        "\n",
        "    #convert lists to np arrays\n",
        "    X_batch = np.array(X_batch)\n",
        "    y_batch = np.array(y_batch)\n",
        "    #return the lists\n",
        "    return (X_batch , y_batch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "EPCW0q_VO266"
      },
      "outputs": [],
      "source": [
        "#simple autoencoder with Dense layers\n",
        "\n",
        "class Autoencoder(Model) :\n",
        "  def __init__(self , hidden_size , latent_size , input_size) :\n",
        "    super(Autoencoder ,self).__init__()\n",
        "\n",
        "    #encoder\n",
        "    self.encoder = Sequential([\n",
        "        Input(shape = input_size) ,       #input layer with shape the shape of the mnist images\n",
        "        Flatten() ,                       #flatten layer to flatten the input to a vector of elements\n",
        "        Dense(hidden_size, activation = \"relu\") ,         #dense layer with hidden_size number of neurons\n",
        "        Dense(latent_size , activation = \"tanh\")          #latent space layer where we get the encoded representation of the image\n",
        "    ])\n",
        "\n",
        "    self.encoder.summary()            #summary of the encoder model\n",
        "\n",
        "    #decoder\n",
        "    self.decoder = Sequential([\n",
        "        Input(shape = self.encoder.output.shape),                     #input layer with shape the shape of the output of the encoder\n",
        "        Dense(hidden_size , activation = \"relu\"),                     #dense layer with hidden_size number of neurons\n",
        "        Dense(input_size[0]*input_size[1] , activation = \"relu\"),     #output layer with 28*28 number of neurons\n",
        "        Reshape(input_size)                                           #reshape layer to get back the image\n",
        "    ])\n",
        "\n",
        "    self.decoder.summary()          #summary of the decoder model\n",
        "\n",
        "  def call(self , x) :\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "VhpNBbMoO4Xo"
      },
      "outputs": [],
      "source": [
        "#simple multilayer perceptron model for the mnist dataset\n",
        "\n",
        "#the constructor takes 2 input arguements , the input size and a list of tupples called layers.\n",
        "#Every tupple in the list has a number which corresponds to the number of neurons for the layer\n",
        "#and a string which specifies the activation function\n",
        "\n",
        "#NOTE I  : the input to this neural network is a 28*28 image which is then flattened\n",
        "#NOTE II : the layers are the hidden layers , since the input layer is defined by the input size and the Input and Flatten layers.\n",
        "\n",
        "class MLP(Model):\n",
        "\n",
        "  def __init__(self , input_size , layers) :\n",
        "    super(MLP , self).__init__()\n",
        "\n",
        "    self.model = Sequential()\n",
        "    self.model.add(Input(shape = input_size))\n",
        "    self.model.add(Flatten())\n",
        "    for i in range(len(layers)) :\n",
        "        self.model.add(Dense(layers[i][0] , activation = layers[i][1]))\n",
        "\n",
        "\n",
        "  def call(self , x) :\n",
        "    out = self.model(x)\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "M3b-KLk-O6BC"
      },
      "outputs": [],
      "source": [
        "#convolutional autoencoder (this is the upgraded version of the simple autoencoder)\n",
        "\n",
        "class CAE(Model):\n",
        "  def __init__(self):\n",
        "    super(CAE, self).__init__()\n",
        "    self.encoder = tf.keras.Sequential([\n",
        "      Input(shape=(28, 28, 1)),\n",
        "      Conv2D(16, (3, 3), activation='relu', padding='same', strides=2),\n",
        "      Conv2D(8, (3, 3), activation='tanh', padding='same', strides=2)\n",
        "      ])\n",
        "\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "      Conv2DTranspose(8, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
        "      Conv2DTranspose(16, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
        "      Conv2D(1, kernel_size=(3, 3), activation='relu', padding='same')])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "oHUN9tbaO7hF"
      },
      "outputs": [],
      "source": [
        "#a convolutional neural network (upgraded version of the multilayer perceptron)\n",
        "\n",
        "\n",
        "class CNN(Model):\n",
        "\n",
        "  def __init__(self) :\n",
        "    super(CNN , self).__init__()\n",
        "\n",
        "    self.model = Sequential()\n",
        "    self.model.add(Conv2D(16 , kernel_size = (3 , 3) , strides = (1 , 1) , input_shape = (28 , 28 , 1) , activation = \"relu\"))\n",
        "    self.model.add(MaxPooling2D(pool_size = (2 , 2)))\n",
        "    self.model.add(Conv2D(32 , kernel_size = (3 , 3) , strides = (1 , 1) , input_shape = (28 , 28 , 1) , activation = \"relu\"))\n",
        "    self.model.add(MaxPooling2D(pool_size = (2 , 2)))\n",
        "    self.model.add(Conv2D(16 , kernel_size = (3 , 3) , strides = (1 , 1) , input_shape = (28 , 28 , 1) , activation = \"relu\"))\n",
        "    self.model.add(Flatten())\n",
        "    self.model.add(Dense(10 , activation = \"softmax\"))\n",
        "\n",
        "  def call(self , x) :\n",
        "    out = self.model(x)\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9GJaimIoZ6g"
      },
      "source": [
        "**Multilayer perceptron models and denoising**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FD7bwh1PO-ki"
      },
      "outputs": [],
      "source": [
        "#train an mlp network for the mnist dataset\n",
        "\n",
        "#define the arcitecture\n",
        "input_size = X_train.shape[1:]\n",
        "print(input_size)\n",
        "hidden_layers = [(300 , \"relu\") , (10 , \"softmax\")]\n",
        "\n",
        "#instantiate model class\n",
        "mlp = MLP(input_size , hidden_layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "qKDSrJj3PARx"
      },
      "outputs": [],
      "source": [
        "#define loss and optimizer\n",
        "loss_mlp = tf.keras.losses.CategoricalCrossentropy()\n",
        "optimizer_mlp = tf.keras.optimizers.Adam()\n",
        "#define number of epochs and batch size and early stopping callback to avoid overfitting\n",
        "epochs = 25\n",
        "batch_size = 128\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\" , patience = 5)\n",
        "#compile the model\n",
        "mlp.compile(loss = loss_mlp , optimizer = optimizer_mlp , metrics = [\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWr0_R4APBsa"
      },
      "outputs": [],
      "source": [
        "#train the mlp network to the original data\n",
        "mlp.fit(X_train , y_train , epochs = epochs , batch_size = batch_size , validation_split = 0.1 , callbacks =[early_stopping_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axV1kwSQPDEz"
      },
      "outputs": [],
      "source": [
        "#test it\n",
        "mlp.evaluate(X_test , y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nf1HAjkcPErg"
      },
      "outputs": [],
      "source": [
        "#train an autoencoder to remove noise from the noisy data we created\n",
        "\n",
        "hidden_size = 200\n",
        "latent_size = 50\n",
        "#define loss and optimizer for the autoencoder\n",
        "loss_autoencoder = tf.keras.losses.MeanSquaredError()\n",
        "optimizer_autoencoder = tf.keras.optimizers.Adam()\n",
        "#create the model\n",
        "input_size = X_train.shape[1:]\n",
        "autoencoder = Autoencoder(hidden_size , latent_size , input_size)\n",
        "autoencoder.compile(optimizer = optimizer_autoencoder, loss = loss_autoencoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIGh0QPFPF2u"
      },
      "outputs": [],
      "source": [
        "#train the autoencoder with the noisy data\n",
        "autoencoder.fit(X_train_noisy , X_train , epochs = 50 , batch_size = 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46O0zrEaPINy"
      },
      "outputs": [],
      "source": [
        "#noisy images denoised\n",
        "encoded_imgs = autoencoder.encoder(X_test_noisy)\n",
        "decoded_imgs = autoencoder.decoder(encoded_imgs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Mpnme2VPIqj"
      },
      "outputs": [],
      "source": [
        "#print some reconstucted images to test the autoencoder\n",
        "\n",
        "n = 11\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "\n",
        "    # display original + noise\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.title(\"original\")\n",
        "    plt.imshow(tf.squeeze(X_test_noisy[i]))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    bx = plt.subplot(2, n, i + n + 1)\n",
        "    plt.title(\"reconstructed\")\n",
        "    plt.imshow(tf.squeeze(decoded_imgs[i]))\n",
        "    plt.gray()\n",
        "    bx.get_xaxis().set_visible(False)\n",
        "    bx.get_yaxis().set_visible(False)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGWfWXjsPJ_c"
      },
      "outputs": [],
      "source": [
        "#test the mlp on the reconstructed denoised images\n",
        "mlp.evaluate(decoded_imgs , y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr1Uu83nRYoh"
      },
      "source": [
        "**Convolutional models and denoising**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "eHg6wyFkPR9K"
      },
      "outputs": [],
      "source": [
        "#we do the exact same things we did with the simple autoencoder and mlp model but with the convolutional models we created\n",
        "\n",
        "#instantiate cnn\n",
        "cnn = CNN()\n",
        "#define loss and optimizer\n",
        "loss_cnn = tf.keras.losses.CategoricalCrossentropy()\n",
        "optimizer_cnn = tf.keras.optimizers.Adam()\n",
        "\n",
        "#define epochs and batch size\n",
        "epochs = 20\n",
        "batch_size = 128\n",
        "cnn.compile(loss = loss_cnn , optimizer = optimizer_cnn , metrics = [\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAMVpKO4PTdP"
      },
      "outputs": [],
      "source": [
        "#train with the original data\n",
        "cnn.fit(X_train , y_train , epochs = epochs , batch_size = batch_size , validation_split = 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzkpBdAlPVEM"
      },
      "outputs": [],
      "source": [
        "#test\n",
        "cnn.evaluate(X_test , y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "ionUe4-PPXPb"
      },
      "outputs": [],
      "source": [
        "#create a convolutional autoencoder\n",
        "\n",
        "cae = CAE()\n",
        "\n",
        "loss_cae = tf.keras.losses.MeanSquaredError()\n",
        "optimizer_cae = tf.keras.optimizers.Adam()\n",
        "epochs = 50\n",
        "batch_size = 128\n",
        "cae.compile(loss = loss_cae , optimizer = optimizer_cae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLC336fCPXvi"
      },
      "outputs": [],
      "source": [
        "#train\n",
        "cae.fit(X_train_noisy , X_train, epochs = epochs , batch_size = batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWMWObglPZCW"
      },
      "outputs": [],
      "source": [
        "#noisy images denoised\n",
        "encoded_imgs = cae.encoder(X_test_noisy)\n",
        "decoded_imgs = cae.decoder(encoded_imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gI_zX8dcPaWj"
      },
      "outputs": [],
      "source": [
        "#evaluate the cnn model using the decoded images as input\n",
        "cnn.evaluate(decoded_imgs , y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Y7uBbRNigfj"
      },
      "outputs": [],
      "source": [
        "#evaluate the mlp model using the decoded images as input\n",
        "mlp.evaluate(decoded_imgs , y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eko1F7fcPcvY"
      },
      "outputs": [],
      "source": [
        "#plot some of the images\n",
        "n = 11\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "\n",
        "    # display original + noise\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.title(\"original\")\n",
        "    plt.imshow(tf.squeeze(X_test_noisy[i]))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    bx = plt.subplot(2, n, i + n + 1)\n",
        "    plt.title(\"reconstructed\")\n",
        "    plt.imshow(tf.squeeze(decoded_imgs[i]))\n",
        "    plt.gray()\n",
        "    bx.get_xaxis().set_visible(False)\n",
        "    bx.get_yaxis().set_visible(False)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVCuBZNvEoIh"
      },
      "source": [
        "**Reconstruction with Principle Component Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GcwOZ38qxK6"
      },
      "outputs": [],
      "source": [
        "#pca as a method of reconstruction of images (no denoising)\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "X_train_flat = np.reshape(X_train , (60_000, 28*28))      #flatten the images\n",
        "X_test_flat = np.reshape(X_test, (10_000 , 28*28))\n",
        "\n",
        "#perform pca and keep the first n components\n",
        "n = 300\n",
        "pca = PCA(n)\n",
        "pca.fit(X_train_flat)\n",
        "#apply the transformation\n",
        "X_train_flat = pca.transform(X_train_flat)\n",
        "X_test_flat = pca.transform(X_test_flat)\n",
        "#reconstruct the images with the inverse transform\n",
        "reconstructed = pca.inverse_transform(X_test_flat)\n",
        "print(f\"Percentage of variance = {sum(pca.explained_variance_ratio_)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkpBNY4_tP6E"
      },
      "outputs": [],
      "source": [
        "#plot some of the images\n",
        "n = 11\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "\n",
        "    # display original + noise\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.title(\"original\")\n",
        "    plt.imshow(tf.squeeze(X_test[i]))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    bx = plt.subplot(2, n, i + n + 1)\n",
        "    plt.title(\"reconstructed\")\n",
        "    plt.imshow(reconstructed[i].reshape((28,28)))\n",
        "    plt.gray()\n",
        "    bx.get_xaxis().set_visible(False)\n",
        "    bx.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
